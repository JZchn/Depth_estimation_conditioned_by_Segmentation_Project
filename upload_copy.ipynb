{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note\n",
        "This project uses the Segment Anything Model (SAM) and Depth Anything Metric version\n",
        "with publicly available pre-trained weights for feature extraction.\n",
        "\n",
        "This notebook reflects the final implementation of the course project,\n",
        "developed and maintained by the author of this repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import copy\n",
        "import math\n",
        "import open3d as o3d\n",
        "from segment_anything import sam_model_registry, SamPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(5)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "base_path = os.getcwd()\n",
        "image_dir = os.path.join(base_path, \"Data\", \"image\")\n",
        "gt_depth_dir = os.path.join(base_path, \"Data\", \"GT_image\", \"depth_maps\")\n",
        "\n",
        "\n",
        "output_mask_dir = os.path.join(base_path, \"outputs\", \"sam_masks\")\n",
        "test_image_dir = os.path.join(base_path, \"outputs\", \"test\", \"image\")\n",
        "test_mask_dir  = os.path.join(base_path, \"outputs\", \"test\", \"sam_mask\")\n",
        "fused_output_dir = os.path.join(base_path, \"outputs\", \"fused_depth\")\n",
        "\n",
        "for d in [output_mask_dir, test_image_dir, test_mask_dir, fused_output_dir]:\n",
        "    os.makedirs(d, exist_ok=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_gt_depth_tiff(gt_path):\n",
        "    gt = cv2.imread(gt_path, cv2.IMREAD_UNCHANGED)\n",
        "    if gt is None:\n",
        "        raise FileNotFoundError(f\"GT file not found: {gt_path}\")\n",
        "    gt = gt.astype(np.float32)\n",
        "    return gt\n",
        "\n",
        "\n",
        "sam_checkpoint = \"path/to/your/sam_checkpoint.pth\"\n",
        "model_type = \"vit_b\"\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device)\n",
        "predictor = SamPredictor(sam)\n",
        "\n",
        "def generate_mask_with_sam_manual_points(image_path, predictor, save_path=None):\n",
        "    \"\"\"\n",
        "    OpenCV GUI for selecting 3 points on the image to generate a mask using SAM.\n",
        "    \"\"\"\n",
        "\n",
        "    image_bgr = cv2.imread(image_path)\n",
        "    if image_bgr is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "    predictor.set_image(image_rgb)\n",
        "    \n",
        "    clicked_points = []\n",
        "    display_image = image_bgr.copy()\n",
        "    window_name = \"SAM - Click 3 points (Tip -> Middle -> End)\"\n",
        "    \n",
        "    def mouse_callback(event, x, y, flags, param):\n",
        "        nonlocal clicked_points, display_image\n",
        "        if event == cv2.EVENT_LBUTTONDOWN:\n",
        "            clicked_points.append([x, y])\n",
        "            print(f\"Point {len(clicked_points)}: ({x}, {y})\")\n",
        "            \n",
        "\n",
        "            cv2.circle(display_image, (x, y), 5, (0, 0, 255), -1)\n",
        "            \n",
        "\n",
        "            cv2.putText(display_image, str(len(clicked_points)), \n",
        "                       (x + 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                       0.7, (0, 0, 255), 2)\n",
        "            \n",
        "\n",
        "            cv2.imshow(window_name, display_image)\n",
        "            \n",
        "            if len(clicked_points) >= 3:\n",
        "                cv2.putText(display_image, \"3 points selected! Press ENTER to confirm\", \n",
        "                           (20, 40), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                           0.8, (0, 255, 0), 2)\n",
        "                cv2.imshow(window_name, display_image)\n",
        "    \n",
        "\n",
        "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
        "    cv2.resizeWindow(window_name, 1000, 800)\n",
        "    cv2.setMouseCallback(window_name, mouse_callback)\n",
        "    \n",
        "    print(\"Click 3 points on the image. Press ENTER when done, ESC to cancel.\")\n",
        "    \n",
        "\n",
        "    cv2.imshow(window_name, display_image)\n",
        "    \n",
        "\n",
        "    while True:\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "        \n",
        "        if key == 13:  # ENTER\n",
        "            break\n",
        "\n",
        "        elif key == 27:  # ESC\n",
        "            print(\"Selection cancelled by user.\")\n",
        "            cv2.destroyAllWindows()\n",
        "            return None, None\n",
        "        \n",
        "\n",
        "        if len(clicked_points) >= 3:\n",
        "            pass  \n",
        "    \n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "\n",
        "    if len(clicked_points) < 3:\n",
        "        print(f\"Only {len(clicked_points)} points selected. Need 3 points.\")\n",
        "        return None, None\n",
        "    \n",
        "  \n",
        "    points = np.array(clicked_points)\n",
        "    point_labels = np.ones(len(points), dtype=int)\n",
        "    \n",
        "\n",
        "    masks, scores, _ = predictor.predict(\n",
        "        point_coords=points,\n",
        "        point_labels=point_labels,\n",
        "        multimask_output=True\n",
        "    )\n",
        "    best_mask = masks[np.argmax(scores)]\n",
        "    \n",
        "    if save_path:\n",
        "        cv2.imwrite(save_path, (best_mask * 255).astype(np.uint8))\n",
        "        print(f\"Mask saved to: {save_path}\")\n",
        "    \n",
        "    return best_mask, points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_reliability_and_features(img_path, mask_path):\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    \n",
        "    mask = (cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) > 127).astype(np.float32)\n",
        "    mask_blur = cv2.GaussianBlur(mask, (15,15), 5)\n",
        "\n",
        "\n",
        "    h, s, v = cv2.split(img_hsv)\n",
        "    specular = ((v > 220) & (s < 50)).astype(np.float32)\n",
        "\n",
        "\n",
        "    shading = cv2.GaussianBlur(img_gray, (0,0), 15)\n",
        "    shading = (shading - shading.min()) / (shading.max() + 1e-8)\n",
        "\n",
        "\n",
        "    local_std = cv2.blur(img_gray**2,(7,7)) - cv2.blur(img_gray,(7,7))**2\n",
        "    local_std = np.sqrt(np.maximum(local_std, 0))\n",
        "    local_std = local_std / (local_std.max() + 1e-8)\n",
        "\n",
        "\n",
        "    gx = cv2.Sobel(img_gray, cv2.CV_32F, 1, 0, ksize=3)\n",
        "    gy = cv2.Sobel(img_gray, cv2.CV_32F, 0, 1, ksize=3)\n",
        "    grad = np.sqrt(gx**2 + gy**2)\n",
        "    grad = grad / (grad.max() + 1e-8)\n",
        "\n",
        "    w_shading = 0.5\n",
        "    w_texture = 0.1\n",
        "    w_edge = 0.1\n",
        "    w_spec = 0.5\n",
        "\n",
        "    R = (w_shading * shading + w_texture * local_std + w_edge * grad) * (1 - mask_blur)\n",
        "    \n",
        "\n",
        "    R = R * (1 - w_spec * specular)\n",
        "    R = np.clip(R, 0, 1)\n",
        "\n",
        "\n",
        "    features = {\n",
        "        \"Shading\": shading,\n",
        "        \"Texture\": local_std,\n",
        "        \"Edge\": grad,\n",
        "        \"Specular\": specular\n",
        "    }\n",
        "    \n",
        "    return R.astype(np.float32), mask.astype(np.float32), features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_reliability_to_image(img, reliability):\n",
        "\n",
        "    img_f = img.astype(np.float32) / 255.0\n",
        "    img_w = img_f * reliability[..., None]\n",
        "    img_w = np.clip(img_w * 255.0, 0, 255).astype(np.uint8)\n",
        "    return img_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_feature_histogram(features, mask):\n",
        "\n",
        "    instrument = mask > 0.5\n",
        "    tissue = mask <= 0.5\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16,4))\n",
        "    fig.suptitle(\"Feature Discrimination: Instrument vs Tissue\")\n",
        "\n",
        "    for ax, (name, feat) in zip(axes, features.items()):\n",
        "        inst_vals = feat[instrument]\n",
        "        tis_vals  = feat[tissue]\n",
        "\n",
        "        means = [inst_vals.mean(), tis_vals.mean()]\n",
        "        stds  = [inst_vals.std(),  tis_vals.std()]\n",
        "\n",
        "        ax.bar([\"Instrument\", \"Tissue\"], means, yerr=stds, capsize=5)\n",
        "        ax.set_title(name)\n",
        "        ax.set_ylabel(\"Feature Value\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_comprehensive(img_path, depth_raw, depth_guided, depth_gt, reliability, mask):\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def norm(d):\n",
        "        d = np.nan_to_num(d)\n",
        "        return (d - d.min()) / (d.max() - d.min() + 1e-8)\n",
        "\n",
        "\n",
        "    err_raw = np.abs(depth_raw - depth_gt)\n",
        "    err_raw[depth_gt <= 0] = 0\n",
        "    err_weighted = err_raw * reliability\n",
        "\n",
        "\n",
        "    img_weighted = apply_reliability_to_image(cv2.imread(img_path), reliability)\n",
        "    \n",
        "\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(24, 10))\n",
        "    fig.suptitle(f\"Analysis: {os.path.basename(img_path)}\", fontsize=14)\n",
        "\n",
        "\n",
        "    axes[0,0].imshow(img)\n",
        "    axes[0,0].set_title(\"RGB Image\")\n",
        "\n",
        "    axes[0,1].imshow(mask, cmap='gray')\n",
        "    axes[0,1].set_title(\"SAM Mask (Binary)\")\n",
        "\n",
        "    axes[0,2].imshow(img_weighted, cmap=None)\n",
        "    axes[0,2].set_title(\"Guided Input\")\n",
        "\n",
        "    axes[0,3].imshow(norm(depth_gt), cmap='inferno')\n",
        "    axes[0,3].set_title(\"GT Depth\")\n",
        "\n",
        "    axes[0,4].imshow(reliability, cmap='magma')\n",
        "    axes[0,4].set_title(\"Reliability Map\")\n",
        "\n",
        "\n",
        "    axes[1,0].imshow(norm(depth_raw), cmap='inferno')\n",
        "    axes[1,0].set_title(\"Pred Depth (Raw)\")\n",
        "\n",
        "    axes[1,1].imshow(norm(depth_guided), cmap='inferno')\n",
        "    axes[1,1].set_title(\"Pred Depth (Guided)\")\n",
        "\n",
        "    axes[1,2].imshow(norm(err_raw), cmap='jet')\n",
        "    axes[1,2].set_title(\"Abs Error (Raw)\")\n",
        "\n",
        "    axes[1,3].imshow(norm(err_weighted), cmap='jet')\n",
        "    axes[1,3].set_title(\"Weighted Error\")\n",
        "\n",
        "    axes[1,4].axis(\"off\") \n",
        "\n",
        "    for ax in axes.flatten():\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_depth_metrics(\n",
        "    depth_pred,\n",
        "    depth_gt,\n",
        "    valid_mask,\n",
        "    reliability=None\n",
        "):\n",
        "\n",
        "\n",
        "    pred = depth_pred[valid_mask]\n",
        "    gt   = depth_gt[valid_mask]\n",
        "\n",
        "    eps = 1e-8\n",
        "    diff = pred - gt\n",
        "    abs_diff = np.abs(diff)\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "\n",
        "    metrics[\"RMSE\"] = np.sqrt(np.mean(diff ** 2))\n",
        "    metrics[\"MAE\"]  = np.mean(abs_diff)\n",
        "    metrics[\"AbsRel\"] = np.mean(abs_diff / (gt + eps))\n",
        "\n",
        "\n",
        "    if reliability is not None:\n",
        "        w = reliability[valid_mask]\n",
        "\n",
        "        metrics[\"wRMSE\"] = np.sqrt(\n",
        "            np.sum(w * diff ** 2) / (np.sum(w) + eps)\n",
        "        )\n",
        "\n",
        "        metrics[\"wAbsRel\"] = np.sum(\n",
        "            w * abs_diff / (gt + eps)\n",
        "        ) / (np.sum(w) + eps)\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def sample_depth_robust(depth_map, x, y, r=3):\n",
        "\n",
        "    H, W = depth_map.shape\n",
        "    x0, x1 = max(0, x - r), min(W, x + r + 1)\n",
        "    y0, y1 = max(0, y - r), min(H, y + r + 1)\n",
        "\n",
        "    patch = depth_map[y0:y1, x0:x1]\n",
        "    patch = patch[np.isfinite(patch)]\n",
        "\n",
        "    if patch.size == 0:\n",
        "        return np.nan\n",
        "\n",
        "    return np.median(patch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_tool_tilt_from_pred(points, depth_map, eps=1e-3):\n",
        "\n",
        "\n",
        "    depths = []\n",
        "    for (x, y) in points:\n",
        "        z = sample_depth_robust(depth_map, int(x), int(y), r=3)\n",
        "        depths.append(z)\n",
        "\n",
        "    d_tip, d_mid, d_end = depths\n",
        "\n",
        "    if np.any(np.isnan(depths)):\n",
        "        return {\n",
        "            \"valid\": False,\n",
        "            \"reason\": \"invalid_depth_sample\",\n",
        "            \"depths\": depths\n",
        "        }\n",
        "\n",
        "    increasing = (d_tip + eps < d_mid) and (d_mid + eps < d_end)\n",
        "    decreasing = (d_tip > d_mid + eps) and (d_mid > d_end + eps)\n",
        "\n",
        "    if increasing:\n",
        "        return {\n",
        "            \"valid\": True,\n",
        "            \"is_tilted\": True,\n",
        "            \"direction\": \"away_from_camera\",\n",
        "            \"depths\": depths\n",
        "        }\n",
        "\n",
        "    if decreasing:\n",
        "        return {\n",
        "            \"valid\": True,\n",
        "            \"is_tilted\": True,\n",
        "            \"direction\": \"towards_camera\",\n",
        "            \"depths\": depths\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"valid\": True,\n",
        "        \"is_tilted\": False,\n",
        "        \"direction\": \"approximately_parallel_or_uncertain\",\n",
        "        \"depths\": depths\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sys.path.append(os.path.join(base_path, \"Depth-Anything-V2\", \"metric_depth\"))\n",
        "from depth_anything_v2.dpt import DepthAnythingV2\n",
        "\n",
        "checkpoint_file = os.path.join(base_path, \"checkpoints\", \"depth_anything_v2_metric_hypersim_vitb.pth\")\n",
        "model = DepthAnythingV2(\n",
        "    encoder='vitb',\n",
        "    features=128,\n",
        "    out_channels=[96, 192, 384, 768]\n",
        ")\n",
        "model.load_state_dict(torch.load(checkpoint_file, map_location='cpu'))\n",
        "model.to(device).eval()\n",
        "\n",
        "val_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".png\")])\n",
        "sample_files = np.random.choice(val_files, min(3, len(val_files)), replace=False)\n",
        "\n",
        "for fname in tqdm(sample_files):\n",
        "\n",
        "\n",
        "    img_path = os.path.join(test_image_dir, fname)\n",
        "    if not os.path.exists(img_path):\n",
        "        shutil.copy(os.path.join(image_dir, fname), img_path)\n",
        "\n",
        "    mask_path = os.path.join(test_mask_dir, fname)\n",
        "\n",
        "    if not os.path.exists(mask_path):\n",
        "        mask_sam, points = generate_mask_with_sam_manual_points(\n",
        "            img_path, predictor, save_path=mask_path)\n",
        "    else:\n",
        "        mask_sam = (cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) > 127).astype(np.uint8)\n",
        "        points = None\n",
        "\n",
        "\n",
        "    raw_img = cv2.imread(img_path)\n",
        "\n",
        "    gt_path = os.path.join(gt_depth_dir, fname.replace(\".png\", \".tiff\"))\n",
        "    depth_gt = load_gt_depth_tiff(gt_path)\n",
        "    if depth_gt.max() > 50:\n",
        "        depth_gt /= 1000.0\n",
        "\n",
        "\n",
        "    reliability_map, mask_float, features = compute_reliability_and_features(\n",
        "        img_path, mask_path\n",
        "    )\n",
        "\n",
        "    instrument_mask = (mask_float > 0.5).astype(np.uint8)\n",
        "    valid_tissue = (depth_gt > 0) & (instrument_mask == 0)\n",
        "\n",
        "\n",
        "    visualize_feature_histogram(features, mask_float)\n",
        "\n",
        "\n",
        "    depth_raw = model.infer_image(raw_img) \n",
        "\n",
        "    img_weighted = apply_reliability_to_image(raw_img, reliability_map)\n",
        "    depth_guided = model.infer_image(img_weighted) \n",
        "\n",
        "\n",
        "    if points is not None:\n",
        "        tilt_info = analyze_tool_tilt_from_pred(points, depth_guided)\n",
        "\n",
        "        print(\"\\n[Tool Tilt Analysis - Predicted Depth]\")\n",
        "        if tilt_info[\"valid\"]:\n",
        "            d_tip, d_mid, d_end = tilt_info[\"depths\"]\n",
        "            print(f\"  Depths: Tip={d_tip:.4f}, Mid={d_mid:.4f}, End={d_end:.4f}\")\n",
        "            print(f\"  Is tilted: {tilt_info['is_tilted']}\")\n",
        "            print(f\"  Direction: {tilt_info['direction']}\")\n",
        "        else:\n",
        "            print(\"  Tilt analysis failed:\", tilt_info[\"reason\"])\n",
        "\n",
        "\n",
        "    if valid_tissue.sum() > 10:\n",
        "        scale = (\n",
        "            np.median(depth_gt[valid_tissue]) /\n",
        "            (np.median(depth_raw[valid_tissue]) + 1e-8)\n",
        "        )\n",
        "        depth_raw *= scale\n",
        "        depth_guided *= scale\n",
        "\n",
        "\n",
        "    metrics_raw = compute_depth_metrics(\n",
        "        depth_raw,\n",
        "        depth_gt,\n",
        "        valid_tissue,\n",
        "        reliability=reliability_map\n",
        "    )\n",
        "\n",
        "    metrics_guided = compute_depth_metrics(\n",
        "        depth_guided,\n",
        "        depth_gt,\n",
        "        valid_tissue,\n",
        "        reliability=reliability_map\n",
        "    )\n",
        "\n",
        "    print(f\"\"\"\n",
        "    [{fname}]\n",
        "\n",
        "    --- Raw Input ---\n",
        "    RMSE:      {metrics_raw[\"RMSE\"]:.4f}\n",
        "    MAE:       {metrics_raw[\"MAE\"]:.4f}\n",
        "    AbsRel:    {metrics_raw[\"AbsRel\"]:.4f}\n",
        "    wRMSE:     {metrics_raw[\"wRMSE\"]:.4f}\n",
        "    wAbsRel:   {metrics_raw[\"wAbsRel\"]:.4f}\n",
        "\n",
        "    --- Guided Input ---\n",
        "    RMSE:      {metrics_guided[\"RMSE\"]:.4f}\n",
        "    MAE:       {metrics_guided[\"MAE\"]:.4f}\n",
        "    AbsRel:    {metrics_guided[\"AbsRel\"]:.4f}\n",
        "    wRMSE:     {metrics_guided[\"wRMSE\"]:.4f}\n",
        "    wAbsRel:   {metrics_guided[\"wAbsRel\"]:.4f}\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "    visualize_comprehensive(\n",
        "        img_path,\n",
        "        depth_raw,\n",
        "        depth_guided,\n",
        "        depth_gt,\n",
        "        reliability_map,\n",
        "        mask_sam\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
